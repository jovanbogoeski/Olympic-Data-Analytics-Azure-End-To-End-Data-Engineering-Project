# ğŸ… **Olympic-Data-Analytics-Azure-End-To-End-Data-Engineering-Project**

## ğŸ“Œ **Overview**
This project demonstrates an **end-to-end data engineering pipeline on Microsoft Azure**, built around **Olympic Games datasets**.  

The solution ingests raw data, transforms it into structured formats, and enables advanced analytics and dashboarding.  

It follows a **modern data lakehouse architecture** using:  
- **Azure Data Factory**  
- **Azure Databricks**  
- **Azure Data Lake Storage Gen2**  
- **Azure Synapse Analytics**  
- **Power BI**  

---

## ğŸ—ï¸ **Architecture**
<!-- Replace with your diagram path -->

### ğŸ”¹ **Data Source**
Olympic datasets (CSV files such as **Athletes, Coaches, Medals, Teams, EntriesGender**) are used as input.  

### ğŸ”¹ **Data Ingestion (Azure Data Factory)**
- Ingests raw CSV datasets from the source (e.g., GitHub or public repository).  
- Stores them in the **Raw Zone** of Azure Data Lake Storage Gen2.  

### ğŸ”¹ **Raw Data Store (ADLS Gen2)**
- Serves as the **Bronze Layer** in the medallion architecture.  
- Holds unprocessed, raw CSV files.  

### ğŸ”¹ **Transformation (Azure Databricks)**
- Performs **data cleaning** (missing values, schema fixes).  
- Applies **business logic transformations**.  
- Writes curated data to the **Transformed Zone (Silver/Gold layers)** in ADLS Gen2.  

### ğŸ”¹ **Transformed Data (ADLS Gen2)**
- Stores **Delta tables** ready for analytics.  
- Acts as the **single source of truth** for downstream consumption.  

### ğŸ”¹ **Analytics (Azure Synapse Analytics)**
- Connects to **transformed Delta tables** stored in ADLS Gen2.  
- Provides a **SQL analytics layer** for BI tools.  

### ğŸ”¹ **Dashboards (Power BI)**
- Visualizes Olympic data insights such as:  
  - **Medal tallies per country**  
  - **Gender distribution in events**  
  - **Athlete participation trends**  

---

## âš™ï¸ **Technologies Used**
- **Azure Data Factory (ADF)** â†’ Data ingestion pipelines  
- **Azure Data Lake Storage Gen2 (ADLS)** â†’ Raw & transformed zones  
- **Azure Databricks (Delta Lake)** â†’ Cleaning & transformations  
- **Azure Synapse Analytics** â†’ SQL analytics layer  
- **Power BI** â†’ Interactive dashboards & reports  

---

## ğŸš€ **Getting Started**

### âœ… **Prerequisites**
- Azure subscription (**Free Trial** or **Pay-As-You-Go**)  
- Resource group with:  
  - **Data Factory**  
  - **Data Lake Storage Gen2**  
  - **Databricks Workspace**  
  - **Synapse Workspace**  
  - **Power BI Desktop** installed locally  

---

### âš¡ **Steps**

#### 1. **Ingest Data**
- Use **ADF pipelines** to copy raw CSVs from source (GitHub/raw link).  
- Store in **ADLS raw/** zone.  

#### 2. **Transform Data**
- Run **Databricks notebooks** to process raw data.  
- Save results in **Delta format** to ADLS **transformed/** zone.  

#### 3. **Analytics Layer**
- Connect **Synapse** to ADLS Delta tables.  
- Expose **views/tables** for reporting.  

#### 4. **Visualize Insights**
- Import **Synapse datasets** into Power BI.  
- Build **interactive dashboards**.  

---

## ğŸ“š **References**
- [**Azure Data Factory Documentation**](https://learn.microsoft.com/en-us/azure/data-factory/)  
- [**Azure Databricks Documentation**](https://learn.microsoft.com/en-us/azure/databricks/)  
- [**Azure Synapse Analytics Documentation**](https://learn.microsoft.com/en-us/azure/synapse-analytics/)  
- [**Power BI Documentation**](https://learn.microsoft.com/en-us/power-bi/)  
